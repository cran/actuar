\documentclass[x11names,english]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
  \usepackage{amsmath}
  \usepackage[round]{natbib}
  \usepackage{babel}
  \usepackage[scaled=0.9]{helvet}
  \usepackage[sc]{mathpazo}
  \usepackage[noae,inconsolata]{Sweave}
  \usepackage[shortlabels]{enumitem}
  \usepackage{framed}

  %\VignetteIndexEntry{Credibility theory}
  %\VignettePackage{actuar}
  %\SweaveUTF8

  \title{Credibility theory features of \pkg{actuar}}
  \author{Christophe Dutang \\ Université du Mans \\[3ex]
    Vincent Goulet \\ Université Laval \\[3ex]
    Xavier Milhaud \\ Université Claude Bernard Lyon 1 \\[3ex]
    Mathieu Pigeon \\ Université du Québec à Montréal}
  \date{}

  %% Colors
  \usepackage{xcolor}
  \definecolor{link}{rgb}{0,0.4,0.6}             % internal links
  \definecolor{url}{rgb}{0.6,0,0}                % external links
  \definecolor{citation}{rgb}{0,0.5,0}           % citations
  \definecolor{codebg}{named}{LightYellow1}      % R code background

  %% Hyperlinks
  \usepackage{hyperref}
  \hypersetup{%
    pdfauthor={Vincent Goulet},
    colorlinks = {true},
    linktocpage = {true},
    urlcolor = {url},
    linkcolor = {link},
    citecolor = {citation},
    pdfpagemode = {UseOutlines},
    pdfstartview = {Fit},
    bookmarksopen = {true},
    bookmarksnumbered = {true},
    bookmarksdepth = {subsubsection}}

  %% Sweave Sinput and Soutput environments reinitialized to remove
  %% default configuration. Space between input and output blocks also
  %% reduced.
  \DefineVerbatimEnvironment{Sinput}{Verbatim}{}
  \DefineVerbatimEnvironment{Soutput}{Verbatim}{}
  \fvset{listparameters={\setlength{\topsep}{0pt}}}

  %% Environment Schunk redefined as an hybrid of environments
  %% snugshade* and leftbar of framed.sty.
  \makeatletter
  \renewenvironment{Schunk}{%
    \setlength{\topsep}{1pt}
    \def\FrameCommand##1{\hskip\@totalleftmargin
       \vrule width 2pt\colorbox{codebg}{\hspace{3pt}##1}%
      % There is no \@totalrightmargin, so:
      \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
    \MakeFramed {\advance\hsize-\width
      \@totalleftmargin\z@ \linewidth\hsize
      \advance\labelsep\fboxsep
      \@setminipage}%
  }{\par\unskip\@minipagefalse\endMakeFramed}
  \makeatother

  %% Some new commands. Commands \E and \VAR redefined to fit within
  %% the author's writing habits...
  \newcommand{\E}[1]{\mathrm{E}[ #1 ]}
  \newcommand{\pkg}[1]{\textbf{#1}}
  \newcommand{\code}[1]{\texttt{#1}}
  \newcommand{\pt}{{\scriptscriptstyle \Sigma}}

  \bibliographystyle{plainnat}

<<echo=FALSE>>=
library(actuar)
options(width = 57, digits = 4)
@

\begin{document}

\maketitle

\section{Introduction}
\label{sec:introduction}

Credibility models are actuarial tools to distribute premiums fairly
among a heterogeneous group of policyholders (henceforth called
\emph{entities}). More generally, they can be seen as prediction methods
applicable in any setting where repeated measures are made for
subjects with different risk levels.

The credibility theory features of \pkg{actuar} consist of matrix
\code{hachemeister} containing the famous data set of
\cite{Hachemeister_75} and function \code{cm} to fit hierarchical
(including Bühlmann, Bühlmann-Straub), regression and linear Bayes
credibility models. Furthermore, function \code{rcomphierarc} can
simulate portfolios of data satisfying the assumptions of the
aforementioned credibility models; see the \code{"simulation"}
vignette for details.


\section{Hachemeister data set}
\label{sec:hachemeister}

The data set of \cite{Hachemeister_75} consists of private passenger
bodily injury insurance average claim amounts, and the corresponding
number of claims, for five U.S.\ states over 12 quarters between July
1970 and June 1973. The data set is included in the package in the
form of a matrix with 5 rows and 25 columns. The first column contains
a state index, columns 2--13 contain the claim averages and columns
14--25 contain the claim numbers:
<<echo=TRUE>>=
data(hachemeister)
hachemeister
@

\section{Hierarchical credibility model}
\label{sec:hierarchical}

The linear model fitting function of R is \code{lm}. Since credibility
models are very close in many respects to linear models, and since the
credibility model fitting function of \pkg{actuar} borrows much of its
interface from \code{lm}, we named the credibility function \code{cm}.

Function \code{cm} acts as a unified interface for all credibility
models supported by the package. Currently, these are: the
unidimensional models of \cite{Buhlmann_69} and \cite{BS_70}; the
hierarchical model of \cite{Jewell_75} (of which the first two are
special cases); the regression model of \cite{Hachemeister_75},
optionally with the intercept at the barycenter of time
\citep[Section~8.4]{Buhlmann_Gisler}; linear Bayes models. The modular
design of \code{cm} makes it easy to add new models if desired.

This section concentrates on usage of \code{cm} for hierarchical
models.

There are some variations in the formulas of the hierarchical model in
the literature. We compute the credibility premiums as given in
\cite{BJ_87} or \cite{Buhlmann_Gisler}, supporting three types of
estimators of the between variance structure parameters: the unbiased
estimators of \cite{Buhlmann_Gisler} (the default), the slightly
different version of \cite{Ohlsson} and the iterative
pseudo-estimators as found in \cite{LivreVert} or \cite{Goulet_JAP}.

Consider an insurance portfolio where \emph{entities} are classified
into \emph{cohorts}. In our terminology, this is a two-level
hierarchical classification structure. The observations are claim
amounts $S_{ijt}$, where index $i = 1, \dots, I$ identifies the
cohort, index $j = 1, \dots, J_i$ identifies the entity within the
cohort and index $t = 1, \dots, n_{ij}$ identifies the period (usually
a year). To each data point corresponds a weight --- or volume ---
$w_{ijt}$. Then, the best linear prediction for the next period
outcome of a entity based on ratios $X_{ijt} = S_{ijt}/w_{ijt}$ is
\begin{equation}
  \label{eq:hierarchical:premiums}
  \begin{split}
    \hat{\pi}_{ij} &= z_{ij} X_{ijw} + (1 - z_{ij}) \hat{\pi}_i \\
    \hat{\pi}_i    &= z_i X_{izw} + (1 - z_i) m,
  \end{split}
\end{equation}
with the credibility factors
\begin{align*}
  z_{ij}
  &= \frac{w_{ij\pt}}{w_{ij\pt} + s^2/a}, &
  w_{ij\pt}
  &= \sum_{t = 1}^{n_{ij}} w_{ijt} \\
  z_{i}
  &= \frac{z_{i\pt}}{z_{i\pt} + a/b}, &
  z_{i\pt}
  &= \sum_{j = 1}^{J_i} z_{ij}
\end{align*}
and the weighted averages
\begin{align*}
  X_{ijw} &= \sum_{t = 1}^{n_{ij}} \frac{w_{ijt}}{w_{ij\pt}}\, X_{ijt} \\
  X_{izw} &= \sum_{j = 1}^{J_i} \frac{z_{ij}}{z_{i\pt}}\, X_{ijw}.
\end{align*}

The estimator of $s^2$ is
\begin{equation}
  \label{eq:s2}
  \hat{s}^2 = \frac{1}{\sum_{i = 1}^I \sum_{j = 1}^{J_i} (n_{ij} - 1)}
  \sum_{i = 1}^I \sum_{j = 1}^{J_i} \sum_{t = 1}^{n_{ij}}
  w_{ijt} (X_{ijt} - X_{ijw})^2.
\end{equation}

The three types of estimators for the variance components $a$ and $b$
are the following. First, let
\begin{align*}
  A_i
  &= \sum_{j = 1}^{J_i} w_{ij\pt} (X_{ijw} - X_{iww})^2 -
  (J_i - 1) s^2 &
  c_i
  &= w_{i\pt\pt} - \sum_{j = 1}^{J_i} \frac{w_{ij\pt}^2}{w_{i\pt\pt}} \\
  B
  &= \sum_{i = 1}^I z_{i\pt} (X_{izw} - \bar{X}_{zzw})^2 - (I - 1) a &
  d
  &= z_{\pt\pt} - \sum_{i = 1}^I \frac{z_{i\pt}^2}{z_{\pt\pt}},
\end{align*}
with
\begin{equation}
  \label{eq:Xbzzw}
  \bar{X}_{zzw} = \sum_{i = 1}^I \frac{z_{i\pt}}{z_{\pt\pt}}\, X_{izw}.
\end{equation}
(Hence, $\E{A_i} = c_i a$ and $\E{B} = d b$.) Then, the
Bühlmann--Gisler estimators are
\begin{align}
  \label{eq:ac-BG}
  \hat{a}
  &= \frac{1}{I} \sum_{i = 1}^I \max \left( \frac{A_i}{c_i}, 0 \right) \\
  \label{eq:bc-BG}
  \hat{b}
  &= \max \left( \frac{B}{d}, 0 \right),
\end{align}
the Ohlsson estimators are
\begin{align}
  \label{eq:ac-Ohl}
  \hat{a}^\prime
  &= \frac{\sum_{i = 1}^I A_i}{\sum_{i = 1}^I c_i} \\
  \label{eq:bc-Ohl}
  \hat{b}^\prime
  &= \frac{B}{d}
\end{align}
and the iterative (pseudo-)estimators are
\begin{align}
  \label{eq:at}
  \tilde{a}
  &= \frac{1}{\sum_{i = 1}^I (J_i - 1)}
  \sum_{i = 1}^I \sum_{j = 1}^{J_i} z_{ij} (X_{ijw} - X_{izw})^2 \\
  \label{eq:bt}
  \tilde{b}
  &= \frac{1}{I - 1}
  \sum_{i = 1}^I z_i (X_{izw} - X_{zzw})^2,
\end{align}
where
\begin{equation}
  \label{eq:Xzzw}
  X_{zzw} = \sum_{i = 1}^I \frac{z_i}{z_\pt}\, X_{izw}.
\end{equation}
Note the difference between the two weighted averages \eqref{eq:Xbzzw}
and \eqref{eq:Xzzw}. See \cite{cm} for further discussion on this
topic.

Finally, the estimator of the collective mean $m$ is $\hat{m} =
X_{zzw}$.

The credibility modeling function \code{cm} assumes that data is available in
the format most practical applications would use, namely a rectangular
array (matrix or data frame) with entity observations in the rows and
with one or more classification index columns (numeric or character).
One will recognize the output format of \code{rcomphierarc} and its summary
methods.

Then, function \code{cm} works much the same as \code{lm}. It takes in
argument: a formula of the form \code{\~{} terms} describing the
hierarchical interactions in a data set; the data set containing the
variables referenced in the formula; the names of the columns
where the ratios and the weights are to be found in the data set. The
latter should contain at least two nodes in each level and more than
one period of experience for at least one entity. Missing values are
represented by \code{NA}s. There can be entities with no experience
(complete lines of \code{NA}s).

In order to give an easily reproducible example, we group states 1 and
3 of the Hachemeister data set into one cohort and states 2, 4 and 5
into another. This shows that data does not have to be sorted by
level. The fitted model below uses the iterative estimators of the
variance components.
<<echo=TRUE>>=
X <- cbind(cohort = c(1, 2, 1, 2, 2), hachemeister)
fit <- cm(~cohort + cohort:state, data = X,
          ratios = ratio.1:ratio.12,
          weights = weight.1:weight.12,
          method = "iterative")
fit
@

The function returns a fitted model object of class \code{"cm"}
containing the estimators of the structure parameters. To compute the
credibility premiums, one calls a method of \code{predict} for this
class.
<<echo=TRUE>>=
predict(fit)
@

One can also obtain a nicely formatted view of the most important
results with a call to \code{summary}.
<<echo=TRUE>>=
summary(fit)
@

The methods of \code{predict} and \code{summary} can both report for a
subset of the levels by means of an argument \code{levels}.
<<echo=TRUE>>=
summary(fit, levels = "cohort")
predict(fit, levels = "cohort")
@


\section{Bühlmann and Bühlmann--Straub models}
\label{sec:buhlmann}

As mentioned above, the Bühlmann and Bühlmann--Straub models are
simply one-level hierarchical models. In this case, the
Bühlmann--Gisler and Ohlsson estimators of the between variance
parameters are both identical to the usual \cite{BS_70} estimator
\begin{equation}
  \label{eq:a-hat}
  \hat{a} = \frac{w_{\pt\pt}}{w_{\pt\pt}^2 - \sum_{i=1}^I
    w_{i\pt}^2}
  \left(
    \sum_{i=1}^I w_{i\pt} (X_{iw} - X_{ww})^2 - (I - 1) \hat{s}^2
  \right),
\end{equation}
and the iterative estimator
\begin{equation}
  \label{eq:a-tilde}
  \tilde{a} = \frac{1}{I - 1} \sum_{i = 1}^I z_i (X_{iw} - X_{zw})^2
\end{equation}
is better known as the Bichsel--Straub estimator.

To fit the Bühlmann model using \code{cm}, one simply does not
specify any weights.
<<echo=TRUE>>=
cm(~state, hachemeister, ratios = ratio.1:ratio.12)
@

When weights are specified together with a one-level model, \code{cm}
automatically fits the Bühlmann--Straub model to the data. In the
example below, we use the Bichsel--Straub estimator for the between
variance.
<<echo=TRUE>>=
cm(~state, hachemeister, ratios = ratio.1:ratio.12,
   weights = weight.1:weight.12)
@


\section{Regression model of Hachemeister}
\label{sec:regression}

The credibility regression model of \cite{Hachemeister_75} is a generalization of
the Bühlmann--Straub model. If data shows a systematic trend, the
latter model will typically under- or over-estimate the true premium
of an entity. The idea of \citeauthor{Hachemeister_75} was to fit to
the data a regression model where the parameters are a credibility
weighted average of an entity's regression parameters and the group's
parameters.

In order to use \code{cm} to fit a credibility regression model to a
data set, one simply has to supply as additional arguments
\code{regformula} and \code{regdata}. The first one is a formula of
the form \code{\~{} terms} describing the regression model, and the
second is a data frame of regressors. That is, arguments
\code{regformula} and \code{regdata} are in every respect equivalent
to arguments \code{formula} and \code{data} of \code{lm}, with the
minor difference that \code{regformula} does not need to have a left
hand side (and is ignored if present). Below, we fit the model
\begin{displaymath}
  X_{it} = \beta_0 + \beta_1 t + \varepsilon_t, \quad
  t = 1, \dots, 12
\end{displaymath}
to the original data set of \cite{Hachemeister_75}.
<<echo=TRUE>>=
fit <- cm(~state, hachemeister, regformula = ~ time,
          regdata = data.frame(time = 1:12),
          ratios = ratio.1:ratio.12,
          weights = weight.1:weight.12)
fit
@

To compute the credibility premiums, one has to provide the ``future''
values of the regressors as in \code{predict.lm}.
<<echo=TRUE>>=
predict(fit, newdata = data.frame(time = 13))
@

It is well known that the basic regression model has a major drawback:
there is no guarantee that the credibility regression line will lie
between the collective and individual ones. This may lead to grossly
inadequate premiums, as Figure~\ref{fig:state4} shows.

\begin{figure}[t]
  \centering
<<echo=FALSE, fig=TRUE>>=
plot(NA, xlim = c(1, 13), ylim = c(1000, 2000), xlab = "", ylab = "")
x <- cbind(1, 1:12)
lines(1:12, x %*% fit$means$portfolio,
      col = "blue", lwd = 2)
lines(1:12, x %*% fit$means$state[, 4],
      col = "red", lwd = 2, lty = 2)
lines(1:12, x %*% coefficients(fit$adj.models[[4]]),
      col = "darkgreen", lwd = 2, lty = 3)
points(13, predict(fit, newdata = data.frame(time = 13))[4],
       pch = 8, col = "darkgreen")
legend("bottomright",
       legend = c("collective", "individual", "credibility"),
       col = c("blue", "red", "darkgreen"), lty = 1:3)
@
  \caption{Collective, individual and credibility regression lines for
    State 4 of the Hachemeister data set. The point indicates the
    credibility premium.}
  \label{fig:state4}
\end{figure}

The solution proposed by \cite{Buhlmann:regression:1997} is simply to
position the intercept not at time origin, but instead at the
barycenter of time \citep[see also][Section~8.4]{Buhlmann_Gisler}. In
mathematical terms, this essentially amounts to using an orthogonal
design matrix. By setting the argument \code{adj.intercept} to
\code{TRUE} in the call, \code{cm} will automatically fit the
credibility regression model with the intercept at the barycenter of
time. The resulting regression coefficients have little meaning, but
the predictions are sensible.
<<echo=TRUE>>=
fit2 <- cm(~state, hachemeister, regformula = ~ time,
           regdata = data.frame(time = 1:12),
           adj.intercept = TRUE,
           ratios = ratio.1:ratio.12,
           weights = weight.1:weight.12)
summary(fit2, newdata = data.frame(time = 13))
@ %
Figure~\ref{fig:state4:2} shows the beneficient effect of the
intercept adjustment on the premium of State~4.

\begin{figure}[t]
  \centering
<<echo=FALSE, fig=TRUE>>=
plot(NA, xlim = c(1, 13), ylim = c(1000, 2000), xlab = "", ylab = "")
x <- cbind(1, 1:12)
R <- fit2$transition
lines(1:12, x %*% solve(R, fit2$means$portfolio),
      col = "blue", lwd = 2)
lines(1:12, x %*% solve(R, fit2$means$state[, 4]),
      col = "red", lwd = 2, lty = 2)
lines(1:12, x %*% solve(R, coefficients(fit2$adj.models[[4]])),
      col = "darkgreen", lwd = 2, lty = 3)
points(13, predict(fit2, newdata = data.frame(time = 13))[4],
       pch = 8, col = "darkgreen")
legend("bottomright",
       legend = c("collective", "individual", "credibility"),
       col = c("blue", "red", "darkgreen"), lty = 1:3)
@
  \caption{Collective, individual and credibility regression lines for
    State 4 of the Hachemeister data set when the intercept is
    positioned at the barycenter of time. The point indicates the
    credibility premium.}
  \label{fig:state4:2}
\end{figure}

\section{Linear Bayes model}
\label{sec:bayes}

In the pure bayesian approach to the ratemaking problem, we assume
that the observations $X_t$, $t = 1, \dots, n$, of an entity depend on
its risk level $\theta$, and that this risk level is a realization of
an unobservable random variable $\Theta$. The best (in the mean square
sense) approximation to the unknown risk premium
$\mu(\theta) = \E{X_t|\Theta = \theta}$ based on observations
$X_1, \dots, X_n$ is the Bayesian premium
\begin{equation*}
  B_{n + 1} = \E{\mu(\Theta)|X_1, \dots, X_n}.
\end{equation*}
It is then well known \citep{Buhlmann_Gisler,LossModels4e} that for
some combinaisons of distributions, the Bayesian premium is linear and
can written as a credibility premium
\begin{equation*}
  B_{n + 1} = z \bar{X} + (1 - z) m,
\end{equation*}
where $m = \E{\mu(\Theta)}$ and $z = n/(n + K)$ for some constant
$K$.

The combinations of distributions yielding a linear Bayes premium
involve members of the univariate exponential family for the
distribution of $X|\Theta = \theta$ and their natural conjugate for
the distribution of $\Theta$:
\begin{itemize}
\item $X|\Theta = \theta \sim \text{Poisson}(\theta)$, $\Theta \sim
  \text{Gamma}(\alpha, \lambda)$;
\item $X|\Theta = \theta \sim \text{Exponential}(\theta)$, $\Theta \sim
  \text{Gamma}(\alpha, \lambda)$;
\item $X|\Theta = \theta \sim \text{Normal}(\theta, \sigma^2_2)$, $\Theta \sim
  \text{Normal}(\mu, \sigma^2_1)$;
\item $X|\Theta = \theta \sim \text{Bernoulli}(\theta)$, $\Theta \sim
  \text{Beta}(a, b)$;
\item $X|\Theta = \theta \sim \text{Geometric}(\theta)$, $\Theta \sim
  \text{Beta}(a, b)$;
\end{itemize}
and the convolutions
\begin{itemize}
\item $X|\Theta = \theta \sim \text{Gamma}(\tau, \theta)$, $\Theta \sim
  \text{Gamma}(\alpha, \lambda)$;
\item $X|\Theta = \theta \sim \text{Binomial}(\nu, \theta)$, $\Theta \sim
  \text{Beta}(a, b)$;
\item $X|\Theta = \theta \sim \text{Negative Binomial}(r, \theta)$ and
  $\Theta \sim \text{Beta}(a, b)$.
\end{itemize}
\autoref{sec:formulas} provides the complete formulas for the above
combinations of distributions.

In addition, \citet[section~2.6]{Buhlmann_Gisler} show that if
$X|\Theta = \theta \sim \text{Single Parameter Pareto}(\theta, x_0)$ and
$\Theta \sim \text{Gamma}(\alpha, \lambda)$, then the Bayesian
estimator of parameter $\theta$ --- not of the risk premium! --- is
\begin{equation*}
  \hat{\Theta} = \eta \hat{\theta}^{\text{MLE}} +
  (1 - \eta) \frac{\alpha}{\lambda},
\end{equation*}
where
\begin{equation*}
  \hat{\theta}^{\text{MLE}} =
  \frac{n}{\sum_{i = 1}^n \ln (X_i/x_0)}
\end{equation*}
is the maximum likelihood estimator of $\theta$ and
\begin{equation*}
  \eta = \frac{\sum_{i = 1}^n \ln (X_i/x_0)}{%
    \lambda + \sum_{i = 1}^n \ln (X_i/x_0)}
\end{equation*}
is a weight not restricted to $(0, 1)$. (See the
\code{"distributions"} package vignette for details on the Single
Parameter Pareto distribution.)

When argument \code{formula} is \code{"bayes"}, function \code{cm}
computes pure Bayesian premiums --- or estimator in the Pareto/Gamma
case --- for the combinations of distributions above. We identify
which by means of argument \code{likelihood} that must be one of %
\code{"poisson"}, %
\code{"exponential"}, %
\code{"gamma"}, %
\code{"normal"}, %
\code{"bernoulli"}, %
\code{"binomial"}, %
\code{"geometric"}, %
\code{"negative binomial"} or %
\code{"pareto"}. %
The parameters of the distribution of $X|\Theta = \theta$, if any, and
those of the distribution of $\Theta$ are specified using the argument
names (and default values) of \code{dgamma}, \code{dnorm},
\code{dbeta}, \code{dbinom}, \code{dnbinom} or \code{dpareto1}, as
appropriate.

Consider the case where
\begin{align*}
  X|\Theta = \theta &\sim \text{Poisson}(\theta) \\
  \Theta &\sim \text{Gamma}(\alpha, \lambda).
\end{align*}
The posterior distribution of $\Theta$ is
\begin{equation*}
  \Theta|X_1, \dots, X_n \sim \text{Gamma}
  \left(
    \alpha + \sum_{t = 1}^n X_t, \lambda + n
  \right).
\end{equation*}
Therefore, the Bayesian premium is
\begin{align*}
  B_{n + 1}
  &= \E{\mu(\Theta)|X_1, \dots, X_n} \\
  &= \E{\Theta|X_1, \dots, X_n} \\
  &= \frac{\alpha + \sum_{t = 1}^n X_t}{\lambda + n} \\
  &= \frac{n}{n + \lambda}\, \bar{X} +
    \frac{\lambda}{n + \lambda} \frac{\alpha}{\lambda} \\
  &= z \bar{X} + (1 - z) m,
\end{align*}
with $m = \E{\mu(\Theta)} = \E{\Theta} = \alpha/\lambda$ and
\begin{equation*}
  z = \frac{n}{n + K}, \quad K = \lambda.
\end{equation*}
One may easily check that if $\alpha = \lambda = 3$ and
$X_1 = 5, X_2 = 3, X_3 = 0, X_4 = 1, X_5 = 1$, then $B_6 = 1.625$. We
obtain the same result using \code{cm}.
<<echo=TRUE>>=
x <- c(5, 3, 0, 1, 1)
fit <- cm("bayes", x, likelihood = "poisson",
           shape = 3, rate = 3)
fit
predict(fit)
summary(fit)
@

\appendix

\section{Linear Bayes formulas}
\label{sec:formulas}

This appendix provides the main linear Bayes credibility results for
combinations of a likelihood function member of the univariate
exponential family with its natural conjugate. For each combination,
we provide, other than the names of the distributions of
$X|\Theta = \theta$ and $\Theta$:
\begin{itemize}
\item the posterior distribution $\Theta|X_1 = x_1, \dots, X_n = x_n$,
  always of the same type as the prior, only with updated parameters;
\item the risk premium $\mu(\theta) = \E{X|\Theta = \theta}$;
\item the collective premium $m = \E{\mu(\Theta)}$;
\item the Bayesian premium
  $B_{n+1} = \E{\mu(\Theta)|X_1, \dots, X_n}$, always equal to the
  collective premium evaluated at the parameters of the posterior
  distribution;
\item the credibility factor when the Bayesian premium is expressed as
  a credibility premium.
\end{itemize}

%% Compact Listes à puce compactes et sans puce, justement.
\begingroup
\setlist[itemize]{label={},leftmargin=0pt,align=left,nosep}

\subsection{Bernoulli/beta case}

\begin{itemize}
\item $X|\Theta = \theta \sim \text{Bernoulli}(\theta)$
\item $\Theta \sim \text{Beta}(a, b)$
\item $\Theta|X_1 = x_1, \dots, X_n = x_n \sim \text{Beta}(\tilde{a},
  \tilde{b})$
  \begin{align*}
    \tilde{a} &= a + \sum_{t = 1}^n x_t \\
    \tilde{b} &= b + n - \sum_{t = 1}^n x_t
  \end{align*}
\item Risk premium
  \begin{equation*}
    \mu(\theta) = \theta
  \end{equation*}
\item Collective premium
  \begin{equation*}
    m = \frac{a}{a + b}
  \end{equation*}
\item Bayesian premium
  \begin{equation*}
    B_{n + 1} = \frac{a + \sum_{t = 1}^n X_t}{a + b + n}
  \end{equation*}
\item Credibility factor
  \begin{equation*}
    z = \frac{n}{n + a + b}
  \end{equation*}
\end{itemize}

\subsection{Binomial/beta case}

\begin{itemize}
\item $X|\Theta = \theta \sim \text{Binomial}(\nu, \theta)$
\item $\Theta \sim \text{Beta}(a, b)$
\item $\Theta|X_1 = x_1, \dots, X_n = x_n \sim \text{Beta}(\tilde{a},
  \tilde{b})$
  \begin{align*}
    \tilde{a} &= a + \sum_{t = 1}^n x_t \\
    \tilde{b} &= b + n \nu - \sum_{t = 1}^n x_t
  \end{align*}
\item Risk premium
  \begin{equation*}
    \mu(\theta) = \nu \theta
  \end{equation*}
\item Collective premium
  \begin{equation*}
    m = \frac{\nu a}{a + b}
  \end{equation*}
\item Bayesian premium
  \begin{equation*}
    B_{n + 1} = \frac{\nu (a + \sum_{t = 1}^n X_t)}{a + b + n \nu}
  \end{equation*}
\item Credibility factor
  \begin{equation*}
    z = \frac{n}{n + (a + b)/\nu}
  \end{equation*}
\end{itemize}

\subsection{Geometric/Beta case}

\begin{itemize}
\item $X|\Theta = \theta \sim \text{Geometric}(\theta)$
\item $\Theta \sim \text{Beta}(a, b)$
\item $\Theta|X_1 = x_1, \dots, X_n = x_n \sim
  \text{Beta}(\tilde{a}, \tilde{b})$
  \begin{align*}
    \tilde{a} &= a + n \\
    \tilde{b} &= b + \sum_{t = 1}^n x_t
  \end{align*}
\item Risk premium
  \begin{equation*}
    \mu(\theta) = \frac{1 - \theta}{\theta}
  \end{equation*}
\item Collective premium
  \begin{equation*}
    m = \frac{b}{a - 1}
  \end{equation*}
\item Bayesian premium
  \begin{equation*}
    B_{n + 1} = \frac{b + \sum_{t = 1}^n X_t}{a + n - 1}
  \end{equation*}
\item Credibility factor
  \begin{equation*}
    z = \frac{n}{n + a - 1}
  \end{equation*}
\end{itemize}

\subsection{Negative binomial/Beta case}

\begin{itemize}
\item $X|\Theta = \theta \sim \text{Negative binomial}(r, \theta)$
\item $\Theta \sim \text{Beta}(a, b)$
\item $\Theta|X_1 = x_1, \dots, X_n = x_n \sim
  \text{Beta}(\tilde{a}, \tilde{b})$
  \begin{align*}
    \tilde{a} &= a + n r \\
    \tilde{b} &= b + \sum_{t = 1}^n x_t
  \end{align*}
\item Risk premium
  \begin{equation*}
    \mu(\theta) = \frac{r (1 - \theta)}{\theta}
  \end{equation*}
\item Collective premium
  \begin{equation*}
    m = \frac{r b}{a - 1}
  \end{equation*}
\item Bayesian premium
  \begin{equation*}
    B_{n + 1} = \frac{r (b + \sum_{t = 1}^n X_t)}{a + n r - 1}
  \end{equation*}
\item Credibility factor
  \begin{equation*}
    z = \frac{n}{n + (a - 1)/r}
  \end{equation*}
\end{itemize}

\subsection{Poisson/Gamma case}

\begin{itemize}
\item $X|\Theta = \theta \sim \text{Poisson}(\theta)$
\item $\Theta \sim \text{Gamma}(\alpha, \lambda)$
\item $\Theta|X_1 = x_1, \dots, X_n = x_n \sim
  \text{Gamma}(\tilde{\alpha}, \tilde{\lambda})$
  \begin{align*}
    \tilde{\alpha} &= \alpha + \sum_{t = 1}^n x_t \\
    \tilde{\lambda} &= \lambda + n
  \end{align*}
\item Risk premium
  \begin{equation*}
    \mu(\theta) = \theta
  \end{equation*}
\item Collective premium
  \begin{equation*}
    m = \frac{\alpha}{\lambda}
  \end{equation*}
\item Bayesian premium
  \begin{equation*}
    B_{n + 1} = \frac{\alpha + \sum_{t = 1}^n X_t}{\lambda + n}
  \end{equation*}
\item Credibility factor
  \begin{equation*}
    z = \frac{n}{n + \lambda}
  \end{equation*}
\end{itemize}

\subsection{Exponential/Gamma case}

\begin{itemize}
\item $X|\Theta = \theta \sim \text{Exponential}(\theta)$
\item $\Theta \sim \text{Gamma}(\alpha, \lambda)$
\item $\Theta|X_1 = x_1, \dots, X_n = x_n \sim
  \text{Gamma}(\tilde{\alpha}, \tilde{\lambda})$
  \begin{align*}
    \tilde{\alpha} &= \alpha + n \\
    \tilde{\lambda} &= \lambda + \sum_{t = 1}^n x_t
  \end{align*}
\item Risk premium
  \begin{equation*}
    \mu(\theta) = \frac{1}{\theta}
  \end{equation*}
\item Collective premium
  \begin{equation*}
    m = \frac{\lambda}{\alpha - 1}
  \end{equation*}
\item Bayesian premium
  \begin{equation*}
    B_{n + 1} = \frac{\lambda + \sum_{t = 1}^n X_t}{\alpha + n - 1}
  \end{equation*}
\item Credibility factor
  \begin{equation*}
    z = \frac{n}{n + \alpha - 1}
  \end{equation*}
\end{itemize}

\subsection{Gamma/Gamma case}

\begin{itemize}
\item $X|\Theta = \theta \sim \text{Gamma}(\tau, \theta)$
\item $\Theta \sim \text{Gamma}(\alpha, \lambda)$
\item $\Theta|X_1 = x_1, \dots, X_n = x_n \sim
  \text{Gamma}(\tilde{\alpha}, \tilde{\lambda})$
  \begin{align*}
    \tilde{\alpha} &= \alpha + n \tau \\
    \tilde{\lambda} &= \lambda + \sum_{t = 1}^n x_t
  \end{align*}
\item Risk premium
  \begin{equation*}
    \mu(\theta) = \frac{\tau}{\theta}
  \end{equation*}
\item Collective premium
  \begin{equation*}
    m = \frac{\tau \lambda}{\alpha - 1}
  \end{equation*}
\item Bayesian premium
  \begin{equation*}
    B_{n + 1} = \frac{\tau (\lambda + \sum_{t = 1}^n X_t)}{\alpha + n \tau - 1}
  \end{equation*}
\item Credibility factor
  \begin{equation*}
    z = \frac{n}{n + (\alpha - 1)/\tau}
  \end{equation*}
\end{itemize}

\subsection{Normal/Normal case}

\begin{itemize}
\item $X|\Theta = \theta \sim \text{Normal}(\theta, \sigma_2^2)$
\item $\Theta \sim \text{Normal}(\mu, \sigma_1^2)$
\item $\Theta|X_1 = x_1, \dots, X_n = x_n \sim
  \text{Normal}(\tilde{\mu}, \tilde{\sigma}_1^2)$
  \begin{align*}
    \tilde{\mu} &=
      \frac{\sigma_1^2 \sum_{t = 1}^n x_t + \sigma_2^2 \mu}{n \sigma_1^2 +
        \sigma_2^2} \\
    \tilde{\sigma}_1^2 &= \frac{\sigma_1^2 \sigma_2^2}{n
        \sigma_1^2 + \sigma_2^2}
  \end{align*}
\item Risk premium
  \begin{equation*}
    \mu(\theta) = \theta
  \end{equation*}
\item Collective premium
  \begin{equation*}
    m = \mu
  \end{equation*}
\item Bayesian premium
  \begin{equation*}
    B_{n + 1} =
      \frac{\sigma_1^2 \sum_{t = 1}^n X_t + \sigma_2^2 \mu}{n \sigma_1^2 +
        \sigma_2^2}
  \end{equation*}
\item Credibility factor
  \begin{equation*}
    z = \frac{n}{n + \sigma_2^2/\sigma_1^2}
  \end{equation*}
\end{itemize}

\endgroup

\bibliography{actuar}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% coding: utf-8
%%% End:
